{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47679,"status":"ok","timestamp":1745432027449,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"ZCnkbPKbdLqb","outputId":"858b132a-fc88-4209-dba3-7115cf58a555"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!cp -r /content/drive/MyDrive/comp9517/Aerial_Landscapes /content/\n","img_dir = \"/content/Aerial_Landscapes\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1745432027452,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"QNo_PYsFdzYi"},"outputs":[],"source":["import os\n","res_dir = '/content/drive/MyDrive/comp9517/res'\n","os.makedirs(res_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1516,"status":"ok","timestamp":1745432028968,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"2q6NE1GRIEav"},"outputs":[],"source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"FShqGk-Zd2XW"},"source":["# sampling"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1041,"status":"ok","timestamp":1745432030016,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"u_cqY9U9d4nH"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","def generate_train_test_powerlaw_indices(\n","    img_dir,\n","    alpha=1.0,\n","    train_ratio=0.8,\n","    seed=42,\n","    plot=True\n","):\n","    np.random.seed(seed)\n","    class_names = sorted([\n","        d for d in os.listdir(img_dir)\n","        if os.path.isdir(os.path.join(img_dir, d))\n","    ])\n","\n","    train_indices_dict = {}\n","    test_indices_dict = {}\n","    original_train_dict = {}\n","\n","    global_idx = 0  # Track dataset-wide index\n","\n","    for cls_idx, cls in enumerate(class_names):\n","        class_dir = os.path.join(img_dir, cls)\n","        image_files = sorted([\n","            f for f in os.listdir(class_dir)\n","            if f.lower().endswith(('.jpg', '.png'))\n","        ])\n","        class_len = len(image_files)\n","        class_indices = list(range(global_idx, global_idx + class_len))\n","\n","        train_idx, test_idx = train_test_split(\n","            class_indices, train_size=train_ratio, random_state=seed, shuffle=True\n","        )\n","\n","        # Save unmodified train/test\n","        original_train_dict[cls_idx] = train_idx\n","        test_indices_dict[cls_idx] = test_idx\n","\n","        # Power-law on train only\n","        rank = cls_idx + 1\n","        weight = (1 / (rank ** alpha))\n","        weight /= (1 / (1 ** alpha))\n","\n","        n_sample = int(len(train_idx) * weight)\n","        sampled = np.random.choice(train_idx, size=n_sample, replace=False)\n","        train_indices_dict[cls_idx] = sorted(sampled.tolist())\n","\n","        global_idx += class_len\n","\n","    if plot:\n","        _plot_sample_distribution(train_indices_dict, title=f\"Train Distribution After Power-Law (Î± = {alpha})\")\n","        _plot_sample_distribution(test_indices_dict, title=\"Test Distribution (Unmodified)\")\n","\n","    return train_indices_dict, test_indices_dict, original_train_dict\n","\n","def _plot_sample_distribution(index_dict, title=\"Sample Distribution\"):\n","    class_names = list(index_dict.keys())\n","    counts = [len(index_dict[cls]) for cls in class_names]\n","\n","    plt.figure(figsize=(10, 5))\n","    bars = plt.bar(class_names, counts, color='slateblue')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.title(title)\n","    plt.xlabel(\"Class\")\n","    plt.ylabel(\"Number of Samples\")\n","    plt.tight_layout()\n","    plt.grid(axis='y')\n","\n","    for bar, count in zip(bars, counts):\n","        plt.text(\n","            bar.get_x() + bar.get_width() / 2,\n","            bar.get_height() + 5,\n","            str(count),\n","            ha='center',\n","            va='bottom',\n","            fontsize=9\n","        )\n","    plt.savefig(os.path.join(res_dir, f\"{title}.png\"))\n","    plt.close()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":747,"status":"ok","timestamp":1745432030765,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"E-9Y7e39my2m"},"outputs":[],"source":["# moderate a = 1\n","moderate_train_dict, moderate_test_dict, _ = generate_train_test_powerlaw_indices(\n","    img_dir, alpha=1, plot=True\n",")\n","\n","# severe a = 1.5\n","severe_train_dict, severe_test_dict, _ = generate_train_test_powerlaw_indices(\n","    img_dir, alpha=1.5, plot=True\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745432030773,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"S895F0ngHZJ5"},"outputs":[],"source":["import os\n","from torch.utils.data import Subset\n","\n","# Converts a train/test index dictionary into a pytorch subset\n","def get_subset_from_index_dict(dataset, index_dict, root_dir):\n","    path_to_index = {\n","        os.path.relpath(path, root_dir): i\n","        for i, (path, _) in enumerate(dataset.samples)\n","    }\n","\n","    selected_indices = []\n","    for class_name, indices in index_dict.items():\n","        for idx in indices:\n","            rel_path = os.path.join(class_name, f\"{idx:03d}.jpg\")\n","            dataset_idx = path_to_index.get(rel_path)\n","            if dataset_idx is not None:\n","                selected_indices.append(dataset_idx)\n","\n","    return Subset(dataset, selected_indices)"]},{"cell_type":"markdown","metadata":{"id":"AgilZe4s6_Ow"},"source":["# resnet"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1418,"status":"ok","timestamp":1745432032200,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"eV3-W-9uGMX4"},"outputs":[],"source":["import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchvision.models import resnet18, ResNet18_Weights\n","from torch.utils.data import DataLoader, Subset\n","from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","\n","def resnet18_train_baseline(train_indices_dict, test_indices_dict,\n","                            num_classes=15, epoch=5, batch_size=32,\n","                            device='cuda', res_dir='results'):\n","\n","    weights = ResNet18_Weights.DEFAULT\n","    preprocess = weights.transforms()\n","\n","    # dataset and subset construction\n","    full_dataset = datasets.ImageFolder(root=img_dir, transform=preprocess)\n","    imbal_train_indices = [i for indices in train_indices_dict.values() for i in indices]\n","    test_indices = [i for indices in test_indices_dict.values() for i in indices]\n","\n","    imbal_train_dataset = Subset(full_dataset, imbal_train_indices)\n","    test_dataset = Subset(full_dataset, test_indices)\n","\n","    train_loader = DataLoader(imbal_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","    # model setup\n","    model = resnet18(weights=weights)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    model = model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","    # training\n","    for ep in range(epoch):\n","        model.train()\n","        total_loss = 0\n","        for imgs, labels in train_loader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        print(f\"[Epoch {ep+1}] Training Loss: {total_loss:.4f}\")\n","\n","    # evaluation\n","    model.eval()\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for imgs, labels in test_loader:\n","            imgs = imgs.to(device)\n","            outputs = model(imgs)\n","            _, preds = torch.max(outputs, 1)\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(preds.cpu().numpy())\n","\n","    class_names = full_dataset.classes\n","    print(\"Classification Report (ResNet18 baseline):\")\n","    print(classification_report(\n","        y_true, y_pred,\n","        labels=list(range(len(class_names))),\n","        target_names=class_names,\n","        digits=4,\n","        zero_division=0\n","    ))\n","\n","    cm = confusion_matrix(y_true, y_pred)\n","    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n","\n","    title = \"ResNet18 Baseline\"\n","    plt.figure(figsize=(8, 8))\n","    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n","    plt.xlabel(\"Predicted Label\")\n","    plt.ylabel(\"True Label\")\n","    plt.title(f\"Confusion Matrix: {title}\")\n","    plt.tight_layout()\n","    os.makedirs(res_dir, exist_ok=True)\n","    plt.savefig(f'{res_dir}/{title.replace(\" \", \"_\")}.png')\n","    plt.close()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22303,"status":"ok","timestamp":1745432054505,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"P-mIuBsqNE8e","outputId":"a7eec440-1b09-4a79-cf18-7744c4b57260"},"outputs":[{"output_type":"stream","name":"stdout","text":["resnet18 on moderate imbalanced data ...\n","[Epoch 1] Training Loss: 50.9024\n","[Epoch 2] Training Loss: 10.1875\n","[Epoch 3] Training Loss: 4.0619\n","[Epoch 4] Training Loss: 2.6256\n","[Epoch 5] Training Loss: 3.4289\n","Classification Report (ResNet18 baseline):\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.7900    0.9875    0.8778       160\n","     Airport     0.7321    0.9563    0.8293       160\n","       Beach     0.9034    0.9938    0.9464       160\n","        City     0.8579    0.9812    0.9155       160\n","      Desert     0.9444    0.9563    0.9503       160\n","      Forest     0.8939    1.0000    0.9440       160\n","   Grassland     0.9441    0.9500    0.9470       160\n","     Highway     0.9667    0.9062    0.9355       160\n","        Lake     0.9510    0.8500    0.8977       160\n","    Mountain     0.9463    0.8812    0.9126       160\n","     Parking     0.9684    0.9563    0.9623       160\n","        Port     1.0000    0.8625    0.9262       160\n","     Railway     0.9741    0.7063    0.8188       160\n"," Residential     0.9671    0.9187    0.9423       160\n","       River     0.9355    0.7250    0.8169       160\n","\n","    accuracy                         0.9087      2400\n","   macro avg     0.9183    0.9088    0.9082      2400\n","weighted avg     0.9183    0.9087    0.9082      2400\n","\n","resnet18 on severe imbalanced data ...\n","[Epoch 1] Training Loss: 40.8699\n","[Epoch 2] Training Loss: 7.1350\n","[Epoch 3] Training Loss: 2.6998\n","[Epoch 4] Training Loss: 1.2636\n","[Epoch 5] Training Loss: 0.6384\n","Classification Report (ResNet18 baseline):\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.6867    1.0000    0.8142       160\n","     Airport     0.4952    0.9750    0.6568       160\n","       Beach     0.7950    0.9938    0.8833       160\n","        City     0.7760    0.9313    0.8466       160\n","      Desert     0.9006    0.9625    0.9305       160\n","      Forest     0.8920    0.9812    0.9345       160\n","   Grassland     0.9012    0.9125    0.9068       160\n","     Highway     0.9167    0.8250    0.8684       160\n","        Lake     0.9328    0.6937    0.7957       160\n","    Mountain     0.8481    0.8375    0.8428       160\n","     Parking     0.9172    0.9000    0.9085       160\n","        Port     0.9661    0.7125    0.8201       160\n","     Railway     0.8413    0.3312    0.4753       160\n"," Residential     0.9837    0.7562    0.8551       160\n","       River     0.9130    0.3937    0.5502       160\n","\n","    accuracy                         0.8137      2400\n","   macro avg     0.8510    0.8138    0.8059      2400\n","weighted avg     0.8510    0.8137    0.8059      2400\n","\n"]}],"source":["print(\"resnet18 on moderate imbalanced data ...\")\n","resnet18_train_baseline(moderate_train_dict, moderate_test_dict)\n","\n","print(\"resnet18 on severe imbalanced data ...\")\n","resnet18_train_baseline(severe_train_dict, severe_test_dict)"]},{"cell_type":"markdown","metadata":{"id":"97XNsO9G8Ua1"},"source":["# efficientnet_b0"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1745432054511,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"BFD9v9AY8nlY"},"outputs":[],"source":["from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n","\n","def efficientnet_b0_train_baseline(train_indices_dict, test_indices_dict,\n","                                   num_classes=15, epoch=5, batch_size=32,\n","                                   device='cuda', res_dir='results'):\n","\n","    weights = EfficientNet_B0_Weights.DEFAULT\n","    preprocess = weights.transforms()\n","\n","    # Dataset and subset construction\n","    full_dataset = datasets.ImageFolder(root=img_dir, transform=preprocess)\n","    imbal_train_indices = [i for indices in train_indices_dict.values() for i in indices]\n","    test_indices = [i for indices in test_indices_dict.values() for i in indices]\n","\n","    imbal_train_dataset = Subset(full_dataset, imbal_train_indices)\n","    test_dataset = Subset(full_dataset, test_indices)\n","\n","    train_loader = DataLoader(imbal_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","    # Model setup\n","    model = efficientnet_b0(weights=weights)\n","    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n","    model = model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","    # Training loop\n","    for ep in range(epoch):\n","        model.train()\n","        total_loss = 0\n","        for imgs, labels in train_loader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        print(f\"[Epoch {ep+1}] Training Loss: {total_loss:.4f}\")\n","\n","    # Evaluation\n","    model.eval()\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for imgs, labels in test_loader:\n","            imgs = imgs.to(device)\n","            outputs = model(imgs)\n","            _, preds = torch.max(outputs, 1)\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(preds.cpu().numpy())\n","\n","    class_names = full_dataset.classes\n","    print(\"Classification Report (EfficientNet_B0 baseline):\")\n","    print(classification_report(\n","        y_true, y_pred,\n","        labels=list(range(len(class_names))),\n","        target_names=class_names,\n","        digits=4,\n","        zero_division=0\n","    ))\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n","\n","    title = \"EfficientNet_B0 Baseline\"\n","    plt.figure(figsize=(8, 8))\n","    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n","    plt.xlabel(\"Predicted Label\")\n","    plt.ylabel(\"True Label\")\n","    plt.title(f\"Confusion Matrix: {title}\")\n","    plt.tight_layout()\n","    os.makedirs(res_dir, exist_ok=True)\n","    plt.savefig(f'{res_dir}/{title.replace(\" \", \"_\")}.png')\n","    plt.close()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37044,"status":"ok","timestamp":1745432091556,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"9LfksO6eNwMe","outputId":"d1c6b57a-f547-4998-9fd8-0f6f4bf59cc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["efficientnet_b0 on moderate imbalanced data ...\n","[Epoch 1] Training Loss: 125.2052\n","[Epoch 2] Training Loss: 53.8497\n","[Epoch 3] Training Loss: 29.5112\n","[Epoch 4] Training Loss: 15.1639\n","[Epoch 5] Training Loss: 10.0199\n","Classification Report (EfficientNet_B0 baseline):\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.8674    0.9812    0.9208       160\n","     Airport     0.8486    0.9812    0.9101       160\n","       Beach     0.9080    0.9875    0.9461       160\n","        City     0.8977    0.9875    0.9405       160\n","      Desert     0.9333    0.9625    0.9477       160\n","      Forest     0.8290    1.0000    0.9065       160\n","   Grassland     0.9787    0.8625    0.9169       160\n","     Highway     0.9481    0.9125    0.9299       160\n","        Lake     0.9267    0.8688    0.8968       160\n","    Mountain     0.9396    0.8750    0.9061       160\n","     Parking     0.9810    0.9688    0.9748       160\n","        Port     0.9677    0.9375    0.9524       160\n","     Railway     0.9209    0.8000    0.8562       160\n"," Residential     0.9869    0.9437    0.9649       160\n","       River     0.8976    0.7125    0.7944       160\n","\n","    accuracy                         0.9187      2400\n","   macro avg     0.9221    0.9187    0.9176      2400\n","weighted avg     0.9221    0.9187    0.9176      2400\n","\n","efficientnet_b0 on severe imbalanced data ...\n","[Epoch 1] Training Loss: 80.4945\n","[Epoch 2] Training Loss: 36.7940\n","[Epoch 3] Training Loss: 21.2690\n","[Epoch 4] Training Loss: 14.4328\n","[Epoch 5] Training Loss: 10.6398\n","Classification Report (EfficientNet_B0 baseline):\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.5445    0.9938    0.7035       160\n","     Airport     0.4460    0.9812    0.6133       160\n","       Beach     0.7324    0.9750    0.8365       160\n","        City     0.4417    0.9938    0.6115       160\n","      Desert     0.8508    0.9625    0.9032       160\n","      Forest     0.7585    0.9812    0.8556       160\n","   Grassland     0.9200    0.8625    0.8903       160\n","     Highway     0.6667    0.7625    0.7114       160\n","        Lake     0.9492    0.3500    0.5114       160\n","    Mountain     0.8158    0.7750    0.7949       160\n","     Parking     0.7396    0.8875    0.8068       160\n","        Port     0.9524    0.1250    0.2210       160\n","     Railway     1.0000    0.0250    0.0488       160\n"," Residential     1.0000    0.2000    0.3333       160\n","       River     1.0000    0.0125    0.0247       160\n","\n","    accuracy                         0.6592      2400\n","   macro avg     0.7878    0.6592    0.5911      2400\n","weighted avg     0.7878    0.6592    0.5911      2400\n","\n"]}],"source":["print(\"efficientnet_b0 on moderate imbalanced data ...\")\n","efficientnet_b0_train_baseline(moderate_train_dict, moderate_test_dict)\n","\n","print(\"efficientnet_b0 on severe imbalanced data ...\")\n","efficientnet_b0_train_baseline(severe_train_dict, severe_test_dict)"]},{"cell_type":"markdown","metadata":{"id":"A4av69tDY9FF"},"source":["# Performance Boosting"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745432091561,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"2kq9omxGY8oA"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def focal_loss(outputs, targets, alpha=None, gamma=2.0):\n","    ce_loss = F.cross_entropy(outputs, targets, reduction='none')\n","    pt = torch.exp(-ce_loss)\n","    alpha_t = alpha[targets] if alpha is not None else 1.0\n","    return (alpha_t * (1 - pt) ** gamma * ce_loss).mean()\n","\n","def dice_loss(outputs, targets, smooth=1e-5):\n","    num_classes = outputs.size(1)\n","    outputs = F.softmax(outputs, dim=1)\n","\n","    targets_onehot = F.one_hot(targets, num_classes=num_classes).float()\n","\n","    intersection = (outputs * targets_onehot).sum(dim=0)\n","    union = outputs.sum(dim=0) + targets_onehot.sum(dim=0)\n","\n","    dice = (2 * intersection + smooth) / (union + smooth)\n","    return 1 - dice.mean()"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745432091564,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"_Psr9JT1t_Un"},"outputs":[],"source":["import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchvision.models import resnet18, ResNet18_Weights\n","from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n","from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import torch.nn.functional as F\n","\n","def remix_batch(x, y, class_counts, tau=0.5, kappa=0.8, num_classes=15):\n","    batch_size = x.size(0)\n","    idx_perm = torch.randperm(batch_size)\n","    x2, y2 = x[idx_perm], y[idx_perm]\n","\n","    probs = torch.tensor([class_counts.get(int(label.item()), 1) for label in y], dtype=torch.float32)\n","    probs_perm = torch.tensor([class_counts.get(int(label.item()), 1) for label in y2], dtype=torch.float32)\n","\n","    probs = probs / probs.sum()\n","    probs_perm = probs_perm / probs_perm.sum()\n","\n","    lam = np.random.beta(1.0, 1.0)\n","    remix_mask = (probs_perm < kappa * probs).float()\n","    lam_adj = remix_mask * tau + (1 - remix_mask) * lam\n","\n","    lam_adj = lam_adj.view(-1, 1, 1, 1).to(x.device)\n","    x_mix = lam_adj * x + (1 - lam_adj) * x2\n","\n","    lam_adj_flat = remix_mask * tau + (1 - remix_mask) * lam\n","    y_onehot = F.one_hot(y, num_classes=num_classes).float()\n","    y2_onehot = F.one_hot(y2, num_classes=num_classes).float()\n","    y_mix = lam_adj_flat.view(-1, 1).to(x.device) * y_onehot + (1 - lam_adj_flat.view(-1, 1)).to(x.device) * y2_onehot\n","\n","    return x_mix, y_mix\n","\n","def resnet18_train(train_indices_dict, test_indices_dict, loss_type='cross_entropy',\n","                   alpha=None, gamma=2.0, epoch=5,\n","                   lambda_focal=1.0, lambda_dice=0.5,\n","                   augmentation=False, useSampler=False, remix=False,\n","                   rotation_deg=15, crop_scale=(0.8, 1.0),\n","                   tau=0.5, kappa=0.8,\n","                   num_classes=15, batch_size=32, device='cuda', res_dir=res_dir):\n","\n","    weights = ResNet18_Weights.DEFAULT\n","    preprocess = weights.transforms()\n","    image_size = weights.transforms().crop_size[0]\n","\n","    data_augmentation = transforms.Compose([\n","        transforms.RandomResizedCrop(image_size, scale=crop_scale),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=weights.transforms().mean, std=weights.transforms().std)\n","    ])\n","\n","    raw_dataset = datasets.ImageFolder(root=img_dir)\n","    transform_train_dataset = datasets.ImageFolder(root=img_dir, transform=data_augmentation if augmentation else preprocess)\n","    imbal_train_indices = [i for indices in train_indices_dict.values() for i in indices]\n","    imbal_train_dataset = Subset(transform_train_dataset, imbal_train_indices)\n","\n","    train_targets = [raw_dataset.targets[i] for i in imbal_train_indices]\n","    class_counts = Counter(train_targets)\n","\n","    if alpha is None and 'focal' in loss_type:\n","        beta = 0.999\n","        alpha_vals = []\n","        for i in range(num_classes):\n","            count = class_counts.get(i, 1)\n","            eff_num = (1 - beta ** count) / (1 - beta)\n","            alpha_vals.append(1 / eff_num)\n","        alpha_tensor = torch.tensor(alpha_vals, dtype=torch.float32)\n","        alpha_tensor = alpha_tensor / alpha_tensor.sum()\n","        alpha = alpha_tensor.to(device)\n","\n","    if useSampler:\n","        class_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n","        sample_weights = [class_weights[label] for label in train_targets]\n","        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n","        train_loader = DataLoader(imbal_train_dataset, batch_size=batch_size, sampler=sampler, num_workers=4)\n","    else:\n","        train_loader = DataLoader(imbal_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","\n","    transform_test_dataset = datasets.ImageFolder(root=img_dir, transform=preprocess)\n","    test_indices = [i for indices in test_indices_dict.values() for i in indices]\n","    test_dataset = Subset(transform_test_dataset, test_indices)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","    model = resnet18(weights=weights)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    model = model.to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","    for ep in range(epoch):\n","        model.train()\n","        total_loss = 0\n","        for imgs, labels in train_loader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","\n","            if remix:\n","                imgs, labels_soft = remix_batch(imgs, labels, class_counts, tau=tau, kappa=kappa, num_classes=num_classes)\n","                outputs = model(imgs)\n","                log_probs = F.log_softmax(outputs, dim=1)\n","                remix_loss = -(labels_soft * log_probs).sum(dim=1).mean()\n","                hard_labels = labels_soft.argmax(dim=1)\n","\n","                if loss_type == 'focal':\n","                    loss = remix_loss + lambda_focal * focal_loss(outputs, hard_labels, alpha=alpha, gamma=gamma)\n","                elif loss_type == 'dice':\n","                    loss = remix_loss + lambda_dice * dice_loss(outputs, hard_labels)\n","                elif loss_type == 'focal+dice':\n","                    loss = remix_loss + lambda_focal * focal_loss(outputs, hard_labels, alpha=alpha, gamma=gamma) + lambda_dice * dice_loss(outputs, hard_labels)\n","                else:\n","                    loss = remix_loss\n","            else:\n","                outputs = model(imgs)\n","                if loss_type == 'focal':\n","                    loss = focal_loss(outputs, labels, alpha=alpha, gamma=gamma)\n","                elif loss_type == 'dice':\n","                    loss = dice_loss(outputs, labels)\n","                elif loss_type == 'focal+dice':\n","                    loss = lambda_focal * focal_loss(outputs, labels, alpha=alpha, gamma=gamma) + lambda_dice * dice_loss(outputs, labels)\n","                else:\n","                    loss = nn.CrossEntropyLoss()(outputs, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        print(f\"[Epoch {ep+1}] Training Loss: {total_loss:.4f}\")\n","\n","    model.eval()\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for imgs, labels in test_loader:\n","            imgs = imgs.to(device)\n","            outputs = model(imgs)\n","            _, preds = torch.max(outputs, 1)\n","            y_true.extend(labels.numpy())\n","            y_pred.extend(preds.cpu().numpy())\n","\n","    class_names = transform_test_dataset.classes\n","    title = f\"ResNet18 - {loss_type}\" + (\" + aug\" if augmentation else \"\") + (\" + sampler\" if useSampler else \"\") + (\" + remix\" if remix else \"\")\n","    print(f\"Classification Report: {title}\")\n","    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n","\n","    cm = confusion_matrix(y_true, y_pred)\n","    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n","    plt.figure(figsize=(8, 8))\n","    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n","    plt.xlabel(\"Predicted Label\")\n","    plt.ylabel(\"True Label\")\n","    plt.title(f\"Confusion Matrix: {title}\")\n","    plt.tight_layout()\n","    os.makedirs(res_dir, exist_ok=True)\n","    plt.savefig(f'{res_dir}/{title.replace(\" \", \"_\").replace(\"+\", \"plus\")}.png')\n","    plt.close()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78522,"status":"ok","timestamp":1745432170088,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"LB_uFWp0v26P","outputId":"620c21ba-685f-40f1-a2c2-40d67350fe42"},"outputs":[{"output_type":"stream","name":"stdout","text":["resnet18 moderate imbalanced data\n","[Epoch 1] Training Loss: 56.3022\n","[Epoch 2] Training Loss: 9.1129\n","[Epoch 3] Training Loss: 3.7320\n","[Epoch 4] Training Loss: 2.8800\n","[Epoch 5] Training Loss: 2.6117\n","Classification Report: ResNet18 - cross_entropy\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.8290    1.0000    0.9065       160\n","     Airport     0.6515    0.9812    0.7830       160\n","       Beach     0.9034    0.9938    0.9464       160\n","        City     0.8814    0.9750    0.9258       160\n","      Desert     0.9387    0.9563    0.9474       160\n","      Forest     0.8814    0.9750    0.9258       160\n","   Grassland     0.9503    0.9563    0.9533       160\n","     Highway     0.9542    0.9125    0.9329       160\n","        Lake     0.9718    0.8625    0.9139       160\n","    Mountain     0.9783    0.8438    0.9060       160\n","     Parking     1.0000    0.9313    0.9644       160\n","        Port     0.9795    0.8938    0.9346       160\n","     Railway     0.9490    0.5813    0.7209       160\n"," Residential     0.9867    0.9250    0.9548       160\n","       River     0.8750    0.7438    0.8041       160\n","\n","    accuracy                         0.9021      2400\n","   macro avg     0.9153    0.9021    0.9013      2400\n","weighted avg     0.9153    0.9021    0.9013      2400\n","\n","resnet18 moderate imbalanced data - focal ...\n","[Epoch 1] Training Loss: 1.8211\n","[Epoch 2] Training Loss: 0.1698\n","[Epoch 3] Training Loss: 0.0733\n","[Epoch 4] Training Loss: 0.0343\n","[Epoch 5] Training Loss: 0.0159\n","Classification Report: ResNet18 - focal\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.8470    0.9688    0.9038       160\n","     Airport     0.7349    0.9875    0.8427       160\n","       Beach     0.9162    0.9563    0.9358       160\n","        City     0.8844    0.9563    0.9189       160\n","      Desert     0.9012    0.9688    0.9337       160\n","      Forest     0.9390    0.9625    0.9506       160\n","   Grassland     0.9390    0.9625    0.9506       160\n","     Highway     0.9583    0.8625    0.9079       160\n","        Lake     0.9396    0.8750    0.9061       160\n","    Mountain     0.9130    0.9187    0.9159       160\n","     Parking     0.9873    0.9750    0.9811       160\n","        Port     0.9933    0.9313    0.9613       160\n","     Railway     0.9590    0.7312    0.8298       160\n"," Residential     0.9387    0.9563    0.9474       160\n","       River     0.9304    0.6687    0.7782       160\n","\n","    accuracy                         0.9121      2400\n","   macro avg     0.9188    0.9121    0.9109      2400\n","weighted avg     0.9188    0.9121    0.9109      2400\n","\n","resnet18 moderate imbalanced data - focal + dice ...\n","[Epoch 1] Training Loss: 21.4539\n","[Epoch 2] Training Loss: 11.2042\n","[Epoch 3] Training Loss: 10.2940\n","[Epoch 4] Training Loss: 10.0109\n","[Epoch 5] Training Loss: 9.8928\n","Classification Report: ResNet18 - focal+dice\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.8736    0.9938    0.9298       160\n","     Airport     0.8000    0.9750    0.8789       160\n","       Beach     0.9506    0.9625    0.9565       160\n","        City     0.9023    0.9812    0.9401       160\n","      Desert     0.9503    0.9563    0.9533       160\n","      Forest     0.9268    0.9500    0.9383       160\n","   Grassland     0.8908    0.9688    0.9281       160\n","     Highway     0.9419    0.9125    0.9270       160\n","        Lake     0.9586    0.8688    0.9115       160\n","    Mountain     0.8671    0.9375    0.9009       160\n","     Parking     0.9810    0.9688    0.9748       160\n","        Port     0.9806    0.9500    0.9651       160\n","     Railway     0.9840    0.7688    0.8632       160\n"," Residential     0.9870    0.9500    0.9682       160\n","       River     0.9187    0.7063    0.7986       160\n","\n","    accuracy                         0.9233      2400\n","   macro avg     0.9276    0.9233    0.9223      2400\n","weighted avg     0.9276    0.9233    0.9223      2400\n","\n","resnet18 moderate imbalanced data - focal + dice + sampler ...\n","[Epoch 1] Training Loss: 18.2570\n","[Epoch 2] Training Loss: 5.7108\n","[Epoch 3] Training Loss: 4.5803\n","[Epoch 4] Training Loss: 5.0783\n","[Epoch 5] Training Loss: 4.2737\n","Classification Report: ResNet18 - focal+dice + sampler\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.8715    0.9750    0.9204       160\n","     Airport     0.7395    0.9938    0.8480       160\n","       Beach     0.8548    0.9938    0.9191       160\n","        City     0.8571    0.9750    0.9123       160\n","      Desert     0.9444    0.9563    0.9503       160\n","      Forest     0.9059    0.9625    0.9333       160\n","   Grassland     0.9268    0.9500    0.9383       160\n","     Highway     0.9459    0.8750    0.9091       160\n","        Lake     0.9315    0.8500    0.8889       160\n","    Mountain     0.8817    0.9313    0.9058       160\n","     Parking     1.0000    0.9688    0.9841       160\n","        Port     1.0000    0.9187    0.9577       160\n","     Railway     0.9649    0.6875    0.8029       160\n"," Residential     0.9805    0.9437    0.9618       160\n","       River     0.9450    0.6438    0.7658       160\n","\n","    accuracy                         0.9083      2400\n","   macro avg     0.9166    0.9083    0.9065      2400\n","weighted avg     0.9166    0.9083    0.9065      2400\n","\n","resnet18 moderate imbalanced data - focal + dice + augmentation ...\n","[Epoch 1] Training Loss: 21.9403\n","[Epoch 2] Training Loss: 12.0712\n","[Epoch 3] Training Loss: 10.8851\n","[Epoch 4] Training Loss: 9.9342\n","[Epoch 5] Training Loss: 9.9746\n","Classification Report: ResNet18 - focal+dice + aug\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.9349    0.9875    0.9605       160\n","     Airport     0.8619    0.9750    0.9150       160\n","       Beach     0.8681    0.9875    0.9240       160\n","        City     0.8920    0.9812    0.9345       160\n","      Desert     0.9430    0.9313    0.9371       160\n","      Forest     0.8736    0.9938    0.9298       160\n","   Grassland     0.9096    0.9437    0.9264       160\n","     Highway     0.9864    0.9062    0.9446       160\n","        Lake     0.9847    0.8063    0.8866       160\n","    Mountain     0.9006    0.9062    0.9034       160\n","     Parking     0.9357    1.0000    0.9668       160\n","        Port     0.9573    0.9812    0.9691       160\n","     Railway     0.9627    0.8063    0.8776       160\n"," Residential     0.9808    0.9563    0.9684       160\n","       River     0.9426    0.7188    0.8156       160\n","\n","    accuracy                         0.9254      2400\n","   macro avg     0.9289    0.9254    0.9240      2400\n","weighted avg     0.9289    0.9254    0.9240      2400\n","\n","resnet18 moderate imbalanced data - focal + dice + augmentation + sampler ...\n","[Epoch 1] Training Loss: 18.5364\n","[Epoch 2] Training Loss: 6.8280\n","[Epoch 3] Training Loss: 5.2675\n","[Epoch 4] Training Loss: 5.6756\n","[Epoch 5] Training Loss: 4.4371\n","Classification Report: ResNet18 - focal+dice + aug + sampler\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.8814    0.9750    0.9258       160\n","     Airport     0.8207    0.9437    0.8779       160\n","       Beach     0.8387    0.9750    0.9017       160\n","        City     0.8857    0.9688    0.9254       160\n","      Desert     0.9735    0.9187    0.9453       160\n","      Forest     0.9357    1.0000    0.9668       160\n","   Grassland     0.9512    0.9750    0.9630       160\n","     Highway     0.9728    0.8938    0.9316       160\n","        Lake     0.9416    0.9062    0.9236       160\n","    Mountain     0.9400    0.8812    0.9097       160\n","     Parking     0.9873    0.9688    0.9779       160\n","        Port     0.9809    0.9625    0.9716       160\n","     Railway     0.9262    0.8625    0.8932       160\n"," Residential     0.9503    0.9563    0.9533       160\n","       River     0.9487    0.6937    0.8014       160\n","\n","    accuracy                         0.9254      2400\n","   macro avg     0.9290    0.9254    0.9245      2400\n","weighted avg     0.9290    0.9254    0.9245      2400\n","\n"]}],"source":["print(\"resnet18 moderate imbalanced data\")\n","resnet18_train(moderate_train_dict, moderate_test_dict)\n","\n","print(\"resnet18 moderate imbalanced data - focal ...\")\n","resnet18_train(moderate_train_dict, moderate_test_dict, loss_type='focal')\n","\n","print(\"resnet18 moderate imbalanced data - focal + dice ...\")\n","resnet18_train(moderate_train_dict, moderate_test_dict, loss_type='focal+dice')\n","\n","print(\"resnet18 moderate imbalanced data - focal + dice + sampler ...\")\n","resnet18_train(moderate_train_dict, moderate_test_dict, loss_type='focal+dice', useSampler=True)\n","\n","print(\"resnet18 moderate imbalanced data - focal + dice + augmentation ...\")\n","resnet18_train(moderate_train_dict, moderate_test_dict, loss_type='focal+dice', augmentation=True)\n","\n","print(\"resnet18 moderate imbalanced data - focal + dice + augmentation + sampler ...\")\n","resnet18_train(moderate_train_dict, moderate_test_dict, loss_type='focal+dice', augmentation=True, useSampler=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58872,"status":"ok","timestamp":1745432228967,"user":{"displayName":"Fangfei Fan","userId":"16414873928846242899"},"user_tz":-600},"id":"sGrGUXDkyRiD","outputId":"747e6eae-d479-41c1-ee84-23d66ae98a4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["resnet18 severe imbalanced data\n","[Epoch 1] Training Loss: 38.8698\n","[Epoch 2] Training Loss: 7.4976\n","[Epoch 3] Training Loss: 3.0806\n","[Epoch 4] Training Loss: 1.5237\n","[Epoch 5] Training Loss: 0.8865\n","Classification Report: ResNet18 - cross_entropy\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.6987    1.0000    0.8226       160\n","     Airport     0.5200    0.9750    0.6783       160\n","       Beach     0.7949    0.9688    0.8732       160\n","        City     0.7277    0.9688    0.8311       160\n","      Desert     0.9217    0.9563    0.9387       160\n","      Forest     0.8413    0.9938    0.9112       160\n","   Grassland     0.8944    0.9000    0.8972       160\n","     Highway     0.8940    0.8438    0.8682       160\n","        Lake     0.9286    0.7312    0.8182       160\n","    Mountain     0.8256    0.8875    0.8554       160\n","     Parking     0.9724    0.8812    0.9246       160\n","        Port     0.9318    0.7688    0.8425       160\n","     Railway     0.8393    0.2938    0.4352       160\n"," Residential     0.9815    0.6625    0.7910       160\n","       River     0.8947    0.3187    0.4700       160\n","\n","    accuracy                         0.8100      2400\n","   macro avg     0.8444    0.8100    0.7972      2400\n","weighted avg     0.8444    0.8100    0.7972      2400\n","\n","resnet18 severe imbalanced data - focal ...\n","[Epoch 1] Training Loss: 1.0183\n","[Epoch 2] Training Loss: 0.1022\n","[Epoch 3] Training Loss: 0.0284\n","[Epoch 4] Training Loss: 0.0222\n","[Epoch 5] Training Loss: 0.0078\n","Classification Report: ResNet18 - focal\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.7929    0.9812    0.8771       160\n","     Airport     0.4755    0.9688    0.6379       160\n","       Beach     0.8378    0.9688    0.8986       160\n","        City     0.7424    0.9187    0.8212       160\n","      Desert     0.9444    0.9563    0.9503       160\n","      Forest     0.8595    0.9938    0.9217       160\n","   Grassland     0.9202    0.9375    0.9288       160\n","     Highway     0.9328    0.7812    0.8503       160\n","        Lake     0.9127    0.7188    0.8042       160\n","    Mountain     0.8846    0.8625    0.8734       160\n","     Parking     0.9799    0.9125    0.9450       160\n","        Port     0.9481    0.8000    0.8678       160\n","     Railway     0.8571    0.3375    0.4843       160\n"," Residential     0.9910    0.6875    0.8118       160\n","       River     0.8624    0.5875    0.6989       160\n","\n","    accuracy                         0.8275      2400\n","   macro avg     0.8628    0.8275    0.8248      2400\n","weighted avg     0.8628    0.8275    0.8248      2400\n","\n","resnet18 severe imbalanced data - focal + dice ...\n","[Epoch 1] Training Loss: 17.2459\n","[Epoch 2] Training Loss: 10.5097\n","[Epoch 3] Training Loss: 9.6870\n","[Epoch 4] Training Loss: 9.2920\n","[Epoch 5] Training Loss: 9.6783\n","Classification Report: ResNet18 - focal+dice\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.7085    0.9875    0.8251       160\n","     Airport     0.5065    0.9812    0.6681       160\n","       Beach     0.7980    0.9875    0.8827       160\n","        City     0.8631    0.9062    0.8841       160\n","      Desert     0.9308    0.9250    0.9279       160\n","      Forest     0.8986    0.8313    0.8636       160\n","   Grassland     0.7070    0.9500    0.8107       160\n","     Highway     0.9275    0.8000    0.8591       160\n","        Lake     0.9538    0.7750    0.8552       160\n","    Mountain     0.8662    0.8500    0.8580       160\n","     Parking     0.9379    0.9437    0.9408       160\n","        Port     0.9848    0.8125    0.8904       160\n","     Railway     0.9818    0.3375    0.5023       160\n"," Residential     0.9375    0.8438    0.8882       160\n","       River     0.9516    0.3688    0.5315       160\n","\n","    accuracy                         0.8200      2400\n","   macro avg     0.8636    0.8200    0.8125      2400\n","weighted avg     0.8636    0.8200    0.8125      2400\n","\n","resnet18 severe imbalanced data - focal + dice + sampler ...\n","[Epoch 1] Training Loss: 13.0946\n","[Epoch 2] Training Loss: 4.1467\n","[Epoch 3] Training Loss: 2.7690\n","[Epoch 4] Training Loss: 2.5055\n","[Epoch 5] Training Loss: 2.5077\n","Classification Report: ResNet18 - focal+dice + sampler\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.7526    0.8938    0.8171       160\n","     Airport     0.4950    0.9375    0.6479       160\n","       Beach     0.8135    0.9812    0.8895       160\n","        City     0.6295    0.9875    0.7689       160\n","      Desert     0.8571    0.9750    0.9123       160\n","      Forest     0.8061    0.9875    0.8876       160\n","   Grassland     0.9172    0.9000    0.9085       160\n","     Highway     0.9178    0.8375    0.8758       160\n","        Lake     0.9084    0.7438    0.8179       160\n","    Mountain     0.8247    0.7937    0.8089       160\n","     Parking     0.9660    0.8875    0.9251       160\n","        Port     0.9538    0.7750    0.8552       160\n","     Railway     0.9091    0.3750    0.5310       160\n"," Residential     0.9722    0.6562    0.7836       160\n","       River     0.9348    0.2687    0.4175       160\n","\n","    accuracy                         0.8000      2400\n","   macro avg     0.8439    0.8000    0.7898      2400\n","weighted avg     0.8439    0.8000    0.7898      2400\n","\n","resnet18 severe imbalanced data - focal + dice + augmentation ...\n","[Epoch 1] Training Loss: 17.0251\n","[Epoch 2] Training Loss: 11.5708\n","[Epoch 3] Training Loss: 10.0454\n","[Epoch 4] Training Loss: 9.6843\n","[Epoch 5] Training Loss: 9.6600\n","Classification Report: ResNet18 - focal+dice + aug\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.8081    1.0000    0.8939       160\n","     Airport     0.6054    0.9875    0.7506       160\n","       Beach     0.8974    0.8750    0.8861       160\n","        City     0.9080    0.9250    0.9164       160\n","      Desert     0.9112    0.9625    0.9362       160\n","      Forest     0.8325    0.9938    0.9060       160\n","   Grassland     0.9371    0.9313    0.9342       160\n","     Highway     0.8758    0.8812    0.8785       160\n","        Lake     0.9562    0.8187    0.8822       160\n","    Mountain     0.9580    0.7125    0.8172       160\n","     Parking     0.8652    0.9625    0.9112       160\n","        Port     0.8758    0.8812    0.8785       160\n","     Railway     0.9540    0.5188    0.6721       160\n"," Residential     0.9441    0.8438    0.8911       160\n","       River     0.8205    0.6000    0.6931       160\n","\n","    accuracy                         0.8596      2400\n","   macro avg     0.8766    0.8596    0.8565      2400\n","weighted avg     0.8766    0.8596    0.8565      2400\n","\n","resnet18 severe imbalanced data - focal + dice + augmentation + sampler ...\n","[Epoch 1] Training Loss: 13.5512\n","[Epoch 2] Training Loss: 4.1460\n","[Epoch 3] Training Loss: 3.3469\n","[Epoch 4] Training Loss: 2.4955\n","[Epoch 5] Training Loss: 2.9220\n","Classification Report: ResNet18 - focal+dice + aug + sampler\n","              precision    recall  f1-score   support\n","\n"," Agriculture     0.7644    0.9938    0.8641       160\n","     Airport     0.5304    0.9812    0.6886       160\n","       Beach     0.7897    0.9625    0.8676       160\n","        City     0.8623    0.9000    0.8807       160\n","      Desert     0.9603    0.9062    0.9325       160\n","      Forest     0.8571    0.9750    0.9123       160\n","   Grassland     0.9216    0.8812    0.9010       160\n","     Highway     0.8704    0.8812    0.8758       160\n","        Lake     0.9220    0.8125    0.8638       160\n","    Mountain     0.8924    0.8812    0.8868       160\n","     Parking     0.9613    0.9313    0.9460       160\n","        Port     1.0000    0.8812    0.9369       160\n","     Railway     0.9351    0.4500    0.6076       160\n"," Residential     0.9766    0.7812    0.8681       160\n","       River     0.9186    0.4938    0.6423       160\n","\n","    accuracy                         0.8475      2400\n","   macro avg     0.8775    0.8475    0.8449      2400\n","weighted avg     0.8775    0.8475    0.8449      2400\n","\n"]}],"source":["print(\"resnet18 severe imbalanced data\")\n","resnet18_train(severe_train_dict, severe_test_dict)\n","\n","print(\"resnet18 severe imbalanced data - focal ...\")\n","resnet18_train(severe_train_dict, severe_test_dict, loss_type='focal', gamma=1.5)\n","\n","print(\"resnet18 severe imbalanced data - focal + dice ...\")\n","resnet18_train(severe_train_dict, severe_test_dict, loss_type='focal+dice', gamma=1.5)\n","\n","print(\"resnet18 severe imbalanced data - focal + dice + sampler ...\")\n","resnet18_train(severe_train_dict, severe_test_dict, loss_type='focal+dice', useSampler=True, gamma=1.5)\n","\n","print(\"resnet18 severe imbalanced data - focal + dice + augmentation ...\")\n","resnet18_train(severe_train_dict, severe_test_dict, loss_type='focal+dice', augmentation=True, gamma=1.5)\n","\n","print(\"resnet18 severe imbalanced data - focal + dice + augmentation + sampler ...\")\n","resnet18_train(severe_train_dict, severe_test_dict, loss_type='focal+dice', augmentation=True, useSampler=True, gamma=1.5)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}